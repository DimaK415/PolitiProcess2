{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cupy.cuda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from Mongo import Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Articles\n",
    "Using my Mongo Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mongo = Connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = mongo.query_df[mongo.query_df['is article'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df = df[df.target ==1].reset_index()\n",
    "blu_df = df[df.target ==0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blu_df.shape, red_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_terms = mongo.db.terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for terms in mongo_terms.find().limit(2).sort([('timestamp', -1)]):\n",
    "    if terms['color'] == 'Blue':\n",
    "        blue = terms\n",
    "    else:\n",
    "        red = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_dict = {}\n",
    "\n",
    "for x in blue:\n",
    "    if 'topic' in x:\n",
    "        terms_dict[x] = []\n",
    "        for y in blue[x]:\n",
    "            terms_dict[x].append(y['term'])\n",
    "\n",
    "terms_df = pd.DataFrame(terms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extras = ['·', '–', '..', '——', '—', '°', '[', ']', '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Processing import Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Embedings\n",
    "The **\"en_core_web_lg\"** is trained as follows:\n",
    "\n",
    "\"English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Assigns word vectors, context-specific token vectors, POS tags, dependency parse and named entities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_threshold = 2\n",
    "rel_art = []\n",
    "topic = terms_df.topic_2\n",
    "\n",
    "for doc in blu_df.text:\n",
    "    doc_score = 0\n",
    "    for term in topic:\n",
    "        if term in doc:\n",
    "            doc_score+=1\n",
    "    if doc_score >= sent_threshold:\n",
    "        rel_art.append(doc)\n",
    "print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rel_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict = {}\n",
    "\n",
    "word_threshold = 1\n",
    "\n",
    "for article in rel_art:\n",
    "    doc = nlp(article)\n",
    "    for sent in doc.sents:\n",
    "        sent_terms = []\n",
    "        for term in terms_df.topic_1:\n",
    "            if term in sent.text:\n",
    "                sent_terms.append(term)\n",
    "            print(sent_terms)\n",
    "                \n",
    "        if len(sent_terms) >= word_threshold:\n",
    "            sent_dict[sent_terms] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence = ''\n",
    "\n",
    "for x in sent_list[4]:\n",
    "    if x.dep_  == 'nsubj':\n",
    "        sentence += x.text + ' '\n",
    "    if x.dep_ == 'ROOT':\n",
    "        print('ROOT ' + x.text)\n",
    "        sentence += x.text + ' '\n",
    "    if x.dep_ in ['dobj', 'obj', 'iobj']:\n",
    "        sentence += x.text + ' '\n",
    "        \n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(blu_df.cleaned[0])\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dict = OrderedDict()\n",
    "for x in doc.ents:\n",
    "    if x.label_ == 'PERSON' and x.text not in ['', ' ']:\n",
    "        sub_dict[x] = 'PERSON'\n",
    "sub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of last name as identifier - solutions:\n",
    "\n",
    "subject_dict = OrderedDict()\n",
    "\n",
    "for sen in:\n",
    "    for x in sent.as_doc().ents:\n",
    "        if x.label_ == 'PERSON':\n",
    "            for y in subject_dict.keys():\n",
    "                print(y)\n",
    "                \n",
    "            subject_dict[x] = x.label_\n",
    "        \n",
    "# subject_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sent_list:\n",
    "    print(x)\n",
    "    for y in x.ent_id_:\n",
    "        if y.ent_type_ == 'PERSON':\n",
    "            print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for y in sent_list:\n",
    "    for x in y:\n",
    "        if x.dep_ == 'ROOT':\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sent_list[1].text)\n",
    "\n",
    "\n",
    "options = {'compact': True, 'bg': '#09a3d5',\n",
    "           'color': 'white', 'font': 'Source Sans Pro'}\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in blue_top_10:\n",
    "    term = term.split()\n",
    "    print(term)\n",
    "#     for article in blu_df.text:\n",
    "#         doc = nlp(article)\n",
    "#         for sent in doc.sents:\n",
    "#             if any(x in sent.text for x in term):\n",
    "#                 if sent.text not in sent_dict[]\n",
    "#                     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        if  token.text in ['James', 'Comey']:\n",
    "            print(token)\n",
    "#                 if token.tag_ == 'NNP' and doc[token.i-1].tag_ == 'NNP':\n",
    "#                     print(doc[token.i-1], token, doc[token.i-1].dep_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for doc in blu_df.text:\n",
    "    if \"Cohen\" in doc:\n",
    "        doc = nlp(doc)\n",
    "        for sent in doc.sents:\n",
    "            for token in sent:\n",
    "                token.tag_\n",
    "                if \"Cohen\" in sent.string:\n",
    "                    print(sent)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vec = {}\n",
    "\n",
    "for doc in blu_df.cleaned:\n",
    "    doc = nlp(doc)\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.is_alpha and not token.has_vector:\n",
    "                if token.text in no_vec.keys():\n",
    "                    no_vec[token.text].append(sent)\n",
    "                else:\n",
    "                    no_vec[token.text] = [sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = {'compact': True, 'bg': '#09a3d5',\n",
    "#            'color': 'white', 'font': 'Source Sans Pro'}\n",
    "displacy.render(sentence.as_doc(), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.get_lca_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vector_set = set(no_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vector_array = np.array(no_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vector_array = np.unique(no_vector_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(no_vector_list), len(no_vector_set), len(no_vector_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(no_vector_list), type(no_vector_set), type(no_vector_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat.BytesIO()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
